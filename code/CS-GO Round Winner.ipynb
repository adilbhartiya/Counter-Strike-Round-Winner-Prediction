{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "830be454",
   "metadata": {},
   "source": [
    "## Step:1 Dataset Description and Objective:\n",
    "\n",
    "**Dataset Description:**\n",
    "\n",
    "`Counter-Strike (CS):` is a popular series of tactical first-person shooter (FPS) video games that have been enjoyed by gamers worldwide for many years. The series originated as a modification for the popular game Half-Life and quickly gained its own dedicated following. Here's an overview of Counter-Strike:\n",
    "\n",
    "`Gameplay Overview:`Counter-Strike is primarily a multiplayer game where two teams, the Counter-Terrorists (CTs) and the Terrorists (Ts), compete against each other.\n",
    "\n",
    "The objective of each round varies based on the game mode, but the primary goals include:\n",
    "\n",
    "`Counter-Terrorists:` Prevent the Terrorists from achieving their objectives, such as defusing a bomb or rescuing hostages.\n",
    "Terrorists: Achieve their objectives, which may include planting a bomb at a designated site or holding hostages.\n",
    "Rounds are relatively short, typically lasting a few minutes, and players have only one life per round. When a player is eliminated, they must wait until the next round to respawn.\n",
    "\n",
    "**Key Features:**\n",
    "\n",
    "`Weapons:` Players can purchase and use a wide variety of firearms, grenades, and equipment. The choice of weaponry is an essential strategic element in the game.\n",
    "\n",
    "`Economy:` Players earn in-game money based on their performance in the previous rounds. Money is used to buy weapons and equipment for the next round.\n",
    "\n",
    "`Maps:` Counter-Strike features a range of maps, each with its own layout and objectives. Popular maps include Dust II, Mirage, Inferno, and more.\n",
    "\n",
    "`Teamwork:` Successful gameplay in Counter-Strike heavily relies on teamwork, communication, and strategy. Players often coordinate their actions with their teammates to achieve objectives.\n",
    "\n",
    "`Competitive Play:` Counter-Strike is well-known for its competitive scene, with professional esports tournaments held worldwide.\n",
    "\n",
    "**Popular Game Modes:**\n",
    "\n",
    "`Bomb Defusal (de_):` In this mode, Terrorists attempt to plant a bomb at one of the designated bomb sites, while Counter-Terrorists aim to prevent the bomb from being planted or defuse it if it's planted.\n",
    "\n",
    "`Hostage Rescue (cs_):` In hostage rescue mode, Counter-Terrorists must rescue hostages held by the Terrorists, while the Terrorists aim to prevent the rescues.\n",
    "\n",
    "`Arms Race:` A fast-paced mode where players cycle through a series of weapons, aiming to be the first to get a kill with each weapon.\n",
    "\n",
    "`Deathmatch:` A mode where players respawn quickly and aim to get as many kills as possible within a set time limit.\n",
    "\n",
    "`Wingman:` A 2v2 competitive mode with smaller maps and shorter rounds.\n",
    "\n",
    "Counter-Strike has evolved over the years with different versions, including Counter-Strike 1.6, Counter-Strike: Source, and Counter-Strike: Global Offensive (CS:GO), which is the most recent and widely played installment as of my last knowledge update in September 2021.\n",
    "\n",
    "CS:GO is known for its competitive gameplay, professional esports scene, and ongoing updates that have kept the game relevant and enjoyable for players worldwide. It remains a cornerstone of the first-person shooter genre.\n",
    "\n",
    "\n",
    "**objective:** \n",
    "The objective of this project is to build and compare multiple machine learning algorithms to classify the round winners in Counter-Strike: Global Offensive (CS). The goal is to analyze the dataset, apply feature selection and engineering, and determine which machine learning models perform best for this classification task. Specifically, we aim to predict the winner of each round based on various in-game attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df13f971",
   "metadata": {},
   "source": [
    "## Step:2 Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de534c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocessing and Model Selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Machine Learning Algorithms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# Evaluation Metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Library for Model Saving and Loading\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab2902f",
   "metadata": {},
   "source": [
    "## Step:3 Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a52ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"E:\\DS & ML Syllabus\\DS and ML projects intellipat\\CS-Go-Project\\cs-go.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a1d531",
   "metadata": {},
   "source": [
    "## Step:4 Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103d29b1",
   "metadata": {},
   "source": [
    "#### 4.1 Data Overview\n",
    "* Checking the dimensions of the dataset (number of rows and columns).\n",
    "* Inspect first few rows to understand the structure of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b173e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure pandas to display a maximum of 10 rows and all columns (unlimited)\n",
    "pd.set_option('display.max_rows',10)\n",
    "pd.set_option('display.max_columns',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acac55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0746e75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display last 5 rows\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18ae50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking shape of dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63636e0b",
   "metadata": {},
   "source": [
    "* so we have 1,22,410 rows and 97 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e89c48",
   "metadata": {},
   "source": [
    "#### 4.2 Checking for Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d2fd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking null values\n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb111cd",
   "metadata": {},
   "source": [
    "#### 4.3 Checking for Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a17ecab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for duplicated values\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac564b8",
   "metadata": {},
   "source": [
    "* We identified 4,962 duplicate records and now we are removing them to ensure a clean dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a57faad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we are removing duplicate rows\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e3c443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now again checking and confirming that no duplicate values present\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7c2b21",
   "metadata": {},
   "source": [
    "#### 4.4 Understanding Data Types and Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade2c9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It helps to understand the data type and information about data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42671c3",
   "metadata": {},
   "source": [
    "* Out of the 97 columns, 94 are of type float64.\n",
    "* The 'bomb_planted' column is of type bool.\n",
    "* The 'map' and 'round_winner' columns are of type object.\n",
    "\n",
    "The 'map' column has 6 different values. Originally, we would apply one-hot encoding to this column. However, due to the large number of columns already present in the dataset, I chose to use label encoding instead to avoid further increasing the number of columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05b9a4c",
   "metadata": {},
   "source": [
    "## Step:5 Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45821f7b",
   "metadata": {},
   "source": [
    "#### 5.1 Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1089eb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dictionary to store the mapping\n",
    "encoded_to_original = {}\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == \"object\" or df[col].dtype == \"bool\":\n",
    "        le = LabelEncoder()\n",
    "        # Fit and transform the column\n",
    "        df[col] = le.fit_transform(df[col]) \n",
    "        # Store the mapping in the dictionary\n",
    "        encoded_to_original[col] = {i: label for i, label in enumerate(le.classes_)}\n",
    "\n",
    "# Now you can access the original labels corresponding to each encoded value for each column\n",
    "encoded_to_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2ce58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f39c6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into independent and dependent variables for applying Feature scaling\n",
    "X=df.iloc[:,:-1]\n",
    "Y=df[\"round_winner\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee22afdd",
   "metadata": {},
   "source": [
    "#### 5.2 Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd212ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Feature scaling in independent variables\n",
    "sc = StandardScaler()\n",
    "X_std = sc.fit_transform(X)\n",
    "X_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b53d2d3",
   "metadata": {},
   "source": [
    "## Step:6  Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94adaf0",
   "metadata": {},
   "source": [
    "#### 6.1 Splitting the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8634f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(X_std,Y,test_size=0.3,random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6f99d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b41851",
   "metadata": {},
   "source": [
    "#### 6.2 Apply Linear Discriminant Analysis\n",
    "* Applying Linear Discriminant Analysis (LDA) for feature selection, because it is a good approach for dimensionality reduction and feature ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a673c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit_transform(x_train,y_train)\n",
    "lda.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85914221",
   "metadata": {},
   "source": [
    "* LDA coefficients are derived from the linear discriminant analysis process \n",
    "* which tells us importance of each column that this column is important to include during model training like that\n",
    "* By analyzing these coefficients, we can interpret the relative importance and impact of each feature in the classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7513e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2792d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So in total we have 96 columns that's why here also we have 96 lda coefficients each coeff. represnting one column\n",
    "# like 1st column time_left holding this much importance 1.28511070e-01\n",
    "# similarly for other 195 columns respectively\n",
    "lda.coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b36f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cf8b1d",
   "metadata": {},
   "source": [
    "* If the LDA coefficients have negative values, as well as when they are in exponential form,\n",
    "* the approach we take is to remove negative values by applying the absolute function.\n",
    "* We then apply a logarithmic transformation to the coefficients to mitigate the risk of encountering\n",
    "* RuntimeWarning: overflow encountered in exp.\n",
    "* Finally, to address the exponential values, we use np.exp to restore the original scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515f6855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the coefficients of LDA have negative values, we take their absolute values\n",
    "# This step removes negative values from the coefficients\n",
    "lda_coefficients_abs = np.abs(lda.coef_)\n",
    "\n",
    "# Apply a logarithmic transformation to the absolute values of the coefficients\n",
    "# This helps to scale down the values and prevent overflow issues\n",
    "lda_coefficients_log = np.log(lda_coefficients_abs)\n",
    "\n",
    "# Apply the exponential function to the transformed coefficients\n",
    "# This restores the original scale while avoiding overflow errors\n",
    "lda_coefficients = np.exp(lda_coefficients_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1f8cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are converting our 2D array into a 1D array by flattening it into a list\n",
    "lda_coefficients=lda_coefficients.flatten()\n",
    "lda_coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5c087e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we are loading all column names into the feature_names variable\n",
    "feature_names=X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cc0d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are plotting a bar graph a/c to lda_coeff and column_names\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.bar(feature_names,lda_coefficients)\n",
    "plt.title(\"Bar graph between lda_coefficients and column_names\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel(\"Features\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e785a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new DataFrame with column names 'Feature_names' and 'feature_scores'\n",
    "df_feature_score = pd.DataFrame({\"Feature_names\":feature_names,\"feature_scores\":lda_coefficients})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c5b79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc92efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now selecting the top 20 columns with the highest feature scores to train our model\n",
    "top_20_values = df_feature_score.nlargest(20,\"feature_scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ceb6853",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9609997e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the indices of these columns to be used in x_train and stored in imp_col\n",
    "imp_col = top_20_values.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f964ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a0bbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating x_train and x_test with the selected columns and converting them into dataframes\n",
    "x_train=x_train[:,imp_col]\n",
    "x_test=x_test[:,imp_col]\n",
    "\n",
    "x_train=pd.DataFrame(x_train)\n",
    "x_test=pd.DataFrame(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466e8d6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e1a9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c437ed",
   "metadata": {},
   "source": [
    "## Step:7 Predictive Model Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9f4efd",
   "metadata": {},
   "source": [
    "### 7.1 Applying Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd3077a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Logistic Regression model\n",
    "lg_model = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "lg_model.fit(x_train, y_train)\n",
    "\n",
    "# Predict using the trained model\n",
    "lg_pred = lg_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3055bd",
   "metadata": {},
   "source": [
    "### 7.2 Applying Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de529476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Decision Tree Classifier model\n",
    "dt_model = DecisionTreeClassifier()\n",
    "\n",
    "# Train the model\n",
    "dt_model.fit(x_train, y_train)\n",
    "\n",
    "# Predict using the trained model\n",
    "dt_pred = dt_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68425827",
   "metadata": {},
   "source": [
    "### 7.3 Applying Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2754d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Random Forest Classifier model\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(x_train, y_train)\n",
    "\n",
    "# Predict using the trained model\n",
    "rf_pred = rf_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687f9df2",
   "metadata": {},
   "source": [
    "## Step:8 Model Evaluation and Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ff397b",
   "metadata": {},
   "source": [
    "#### 8.1 Model Evaluation (Using Accuracy, Precision, Recall, F1-score, and ROC-AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1966e3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Evaluation\n",
    "lg_pred = lg_model.predict(x_test)\n",
    "lg_accuracy = accuracy_score(y_test, lg_pred)\n",
    "lg_precision = precision_score(y_test, lg_pred)\n",
    "lg_recall = recall_score(y_test, lg_pred)\n",
    "lg_f1 = f1_score(y_test, lg_pred)\n",
    "lg_roc_auc = roc_auc_score(y_test, lg_pred)\n",
    "\n",
    "# Decision Tree Classifier Evaluation\n",
    "dt_pred = dt_model.predict(x_test)\n",
    "dt_accuracy = accuracy_score(y_test, dt_pred)\n",
    "dt_precision = precision_score(y_test, dt_pred)\n",
    "dt_recall = recall_score(y_test, dt_pred)\n",
    "dt_f1 = f1_score(y_test, dt_pred)\n",
    "dt_roc_auc = roc_auc_score(y_test, dt_pred)\n",
    "\n",
    "# Random Forest Classifier Evaluation\n",
    "rf_pred = rf_model.predict(x_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
    "rf_precision = precision_score(y_test, rf_pred)\n",
    "rf_recall = recall_score(y_test, rf_pred)\n",
    "rf_f1 = f1_score(y_test, rf_pred)\n",
    "rf_roc_auc = roc_auc_score(y_test, rf_pred)\n",
    "\n",
    "# Print or display evaluation metrics for each model\n",
    "print(\"Logistic Regression Metrics:\")\n",
    "print(\"Accuracy:\", lg_accuracy)\n",
    "print(\"Precision:\", lg_precision)\n",
    "print(\"Recall:\", lg_recall)\n",
    "print(\"F1-score:\", lg_f1)\n",
    "print(\"ROC-AUC:\", lg_roc_auc)\n",
    "print()\n",
    "\n",
    "print(\"Decision Tree Classifier Metrics:\")\n",
    "print(\"Accuracy:\", dt_accuracy)\n",
    "print(\"Precision:\", dt_precision)\n",
    "print(\"Recall:\", dt_recall)\n",
    "print(\"F1-score:\", dt_f1)\n",
    "print(\"ROC-AUC:\", dt_roc_auc)\n",
    "print()\n",
    "\n",
    "print(\"Random Forest Classifier Metrics:\")\n",
    "print(\"Accuracy:\", rf_accuracy)\n",
    "print(\"Precision:\", rf_precision)\n",
    "print(\"Recall:\", rf_recall)\n",
    "print(\"F1-score:\", rf_f1)\n",
    "print(\"ROC-AUC:\", rf_roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f51e5e6",
   "metadata": {},
   "source": [
    "#### 8.2 Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc9e843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing Model Performance based on Sccuracy\n",
    "models_accuracy = {'Logistic Regression': lg_accuracy, 'Decision Tree Classifier': dt_accuracy, 'Random Forest Classifier': rf_accuracy}\n",
    "best_model = max(models_accuracy, key=models_accuracy.get)\n",
    "print(\"Best Model based on Accuracy:\", best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2c0f53",
   "metadata": {},
   "source": [
    "## Step:9 Model Saving and Loading for Scalability and Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb47a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Saving the model\n",
    "# Specify the file path where you want to save the model\n",
    "model_file_path = '../models/random_forest_model.pkl'\n",
    "\n",
    "# Save the model to the specified file path\n",
    "joblib.dump(rf_model, model_file_path)\n",
    "\n",
    "# Step 2: Loading the model\n",
    "# Load the saved model from the file path\n",
    "loaded_model = joblib.load(model_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f757f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Perform predictions using the loaded model\n",
    "# For 1st row from X_test\n",
    "predictions = loaded_model.predict([[-0.002918,-0.002918,-0.054919,-0.168787,-0.940986,1.869350,-1.035043,-0.992892,0.726451,-0.740199,-0.876780,-0.159325,-0.690560,-0.363148,-0.366084,-0.439628,-0.884340,-0.297517,0.612828,-0.479267]])\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0273414",
   "metadata": {},
   "source": [
    "* So here we got output as 1: means round_winner is Terrorist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48272a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 3rd row from X_test\n",
    "# Perform predictions using the loaded model\n",
    "predictions = loaded_model.predict([[-0.002918,-0.002918,0.054203,0.482854,1.984910,-0.742782,0.683520,0.614080,1.544110,-0.528024,2.081069,-0.771821,1.388414,-0.363148,1.268759,-0.439628,-0.844547,-0.297517,1.167441,-0.479267]])\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31f118d",
   "metadata": {},
   "source": [
    "* So here we got output as 0: means round_winner is Counter-Terrorist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2273dc",
   "metadata": {},
   "source": [
    "## Step:10 Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c63c67",
   "metadata": {},
   "source": [
    "In this project, our objective was to utilize machine learning algorithms for classifying round winners in Counter-Strike: Global Offensive (CS). Following thorough data preprocessing, feature selection, and model training, we evaluated three classification algorithms: Logistic Regression, Decision Tree Classifier, and Random Forest Classifier.\n",
    "\n",
    "The evaluation criteria included Accuracy, Precision, Recall, F1-score, and ROC-AUC. Notably, the Random Forest Classifier emerged as the top-performing model, achieving an accuracy of 0.841.\n",
    "\n",
    "Upon analysis, the Random Forest Classifier demonstrated superior performance across all metrics, showcasing its effectiveness in predicting round winners in CS. With strong precision, recall, F1-score, and ROC-AUC values, it stands out as the most reliable choice for this classification task.\n",
    "\n",
    "In conclusion, the Random Forest Classifier offers robust performance in leveraging game attributes for classification. Further optimization and fine-tuning of the model could potentially enhance its performance even more."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
